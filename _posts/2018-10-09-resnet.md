---
layout: post
title: "CIFAR-10 정복 시리즈 1: ResNet"
subtitle: "Deep Residual Learning for Image Recognition"
categories: cifar10
tags: dl
comments: true
---


## CIFAR-10 정복하기 시리즈 소개
CIFAR-10 정복하기 시리즈에서는 딥러닝이 CIFAR-10 데이터셋에서 어떻게 성능을 높여왔는지 그 흐름을 알아본다. 또한 코드를 통해서 동작원리를 자세하게 깨닫고 실습해볼 것이다. 

- CIFAR-10 정복하기 시리즈 목차(클릭해서 바로 이동하기)
  - [CIFAR-10 정복 시리즈 0: 시작하기](https://dnddnjs.github.io/cifar10/2018/10/08/start_cifar10/)
  - [CIFAR-10 정복 시리즈 1: ResNet](https://dnddnjs.github.io/cifar10/2018/10/09/resnet/)
  - [CIFAR-10 정복 시리즈 2: DenseNet](https://dnddnjs.github.io/cifar10/2018/10/11/densenet/)
  - [CIFAR-10 정복 시리즈 3: Wide ResNet](https://dnddnjs.github.io/cifar10/2018/10/12/wide_resnet/)
  - [CIFAR-10 정복 시리즈 4: Shake-shake](https://dnddnjs.github.io/cifar10/2018/10/13/shake_shake/)
  - [CIFAR-10 정복 시리즈 5: PyramidNet](https://dnddnjs.github.io/cifar10/2018/10/24/pyramidnet/)
  - [CIFAR-10 정복 시리즈 6: Shake-Drop](https://dnddnjs.github.io/cifar10/2018/10/19/shake_drop/)
  - [CIFAR-10 정복 시리즈 7: NAS](https://dnddnjs.github.io/cifar10/2018/11/04/nas/)
  - [CIFAR-10 정복 시리즈 8: NASNet](https://dnddnjs.github.io/cifar10/2018/11/03/nasnet/)
  - [CIFAR-10 정복 시리즈 9: Auto-Augment](https://dnddnjs.github.io/cifar10/2018/10/31/autoaugment/)

- 관련 코드 링크
  - [pytorch cifar10 github code](https://github.com/dnddnjs/pytorch-cifar10) 

  
## 논문 제목: Deep Residual Learning for Image Recognition [2015 December]

<img src="https://www.dropbox.com/s/b0dp6tse95zudzw/Screenshot%202018-10-09%2020.54.11.png?dl=1">
- 논문 저자: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun(Microsoft Research)
- 논문 링크: [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)


Resnet은 VGG와 함께 대부분의 Deep-Network에서 기본이 되는 네트워크 구조이다. Resnet 이후의 네트워크 구조는 거의 Resnet의 변형이라고 볼 수 있다. 따라서 이 구조에 대해서 잘 아는 것이 중요하다. 

<br/>

### Abstract

- 이전보다 Deep한 neural network를 training하게 해줌
- 기존 문제를 layer input을 reference로 한 residual function을 학습하는 문제로 바꿈
- 그랬더니 더 최적화하기 쉽고 더 정확도가 높음
- ILSVRC 2015 classification task에서 1등함
- COCO object detection dataset에서 28% 개선

<br/>

### Introduction

- degradation problem: 네트워크 깊이가 증가하는데 정확도는 정체되다가 빠르게 감소하는 현상
  - 이 문제는 overfitting으로 인한 문제가 아님 (왜 그렇지?)
  - 실험적으로 layer가 깊어지면 training error도 증가함

<img src="https://www.dropbox.com/s/06xom9u3umodycz/Screenshot%202018-10-09%2021.16.01.png?dl=1">

- 이 논문에서는 degradation 문제를 해결하기 위해 "deep residual learning" 구조를 제안함
- 원래 H(x) = F(x) 를 mapping 했다면 residual connection을 사용하면 H(x) = F(x) + x를 mapping 함.

<img src="https://www.dropbox.com/s/6acjshs76hb08gj/Screenshot%202018-10-09%2021.20.46.png?dl=1">

- 원래 mapping 보다 residual mapping이 더 최적화하기 쉽다고 가정
- 만약 identity mapping이 최적이면 그저 네트워크를 0이 되게 만들면 됌
- 밑에서 돌아서 위로 붙는 연결을 "shortcut connections"라고 함

<br/>

### Deep Residual Learning

- H(x) = F(x) 에서 H(x) = F(x) + x 로 mapping을 바꾸면 결과적으로 approximate하는 것은 같음. 하지만 학습과정은 상당히 다름
- 이전 실험결과(layer가 늘었을 때 training error가 늘어나는 현상)는 여러 nonlinear layer가 identity mapping을 하기 어려워한다는 것을 보여줌
- 만약 shortcut connection의 dimension이 같다면 다음과 같음
<img src="https://www.dropbox.com/s/wpflqqr7m86osid/Screenshot%202018-10-09%2021.39.11.png?dl=1">

- 만약 shortcut connection의 dimension이 다르다면 다음과 같음
<img src="https://www.dropbox.com/s/zefxlnbgex3pk2g/Screenshot%202018-10-09%2021.39.36.png?dl=1">

- residual function F로 2 layer를 써도 되고 그 이상을 써도 됌. 하지만 1 layer면 direct mapping이랑 비슷함.
- F + x는 fully-connected layer에서는 element-wise addition / convolutional layer에서는 channel-wise addition

- 비교 실험을 하기 위해 plaing baseline을 도입.
  - VGG 형태를 가져옴. 3x3 filter를 사용
  - output feature map size가 같다면 filter 개수도 같음
  - 만일 feature map size가 반으로 줄면 filter 개수는 두 배로 늘림
  - down-sampling은 stride 2 convolution으로 함
  - 마지막에 global-average pooling으로 1000개 class output 만듬

- VGG보다 fewer filters & lower complexity
- 다음은 VGG & Plain net & Resnet 비교 그림

<img src="https://www.dropbox.com/s/eqfw171k9kn7gik/Screenshot%202018-10-09%2021.49.14.png?dl=1">

- 위 그림에서 resnet의 경우 점선으로 표시되는 shortcut이 있음. 이 shortcut은 dimension을 높이는데 1x1 convolution을 사용함.
- Implementation detail
  - 이미지의 짧은 변을 256에서 480 사이의 특정 숫자로 rescale함
  - rescale한 이미지에 대해 224, 224로 random crop
  - horizontal flip 적용
  - per-pixel mean을 뺌
  - standard color augmentation 적용
  - batch normalization 적용
  - SGD with 256 mini batch leraning rate 0.1
  - lr는 error plateou마다 0.1배씩 감소
  - weight decay는 0.0001, SGD momentum은 0.9
  - test 할 때는 10-crop testing
  - multi-scale 사용 (224, 256, 384, 480, 640)
  - training images : 128만개
  - validation images : 5만개
  - test images : 10만개

<br/>

### Experiment
- plain net과 resnet은 18-layer, 34-layer를 테스트함
- Image net에 적용한 네트워크 architecture는 다음과 같음

<img src="https://www.dropbox.com/s/5fawzywoqa4v7wm/Screenshot%202018-10-10%2000.32.49.png?dl=1">

- plain net의 경우 iter & error 그래프에서 34-layer가 더 error가 높은 것을 볼 수 있다.
- resnet의 경우 34-layer가 더 error가 낮을 것을 볼 수 있다.
<img src="https://www.dropbox.com/s/g3uljkfs2eu78w1/Screenshot%202018-10-10%2000.34.43.png?dl=1">

- batch-norm을 통해 forward와 backward에서 signal가 사라지는 것을 방지함
- resnet은 어느정도 degradation 문제를 해결
- 18-layer 정도에서는 plain net과 resnet은 비슷한 성능을 보임. resnet-18이 좀 더 빠르게 수렴한다는데 별 차이없어 보임.
- 제대로 resnet을 활용하려면 resnet-34 이상을 쓰는 것이 좋아 보임. resnet-152 까지는 깊게 쌓을수록 더 성능이 좋아짐. 34, 50, 101, 152는 magic number가 아닌가 싶음.
- 다음은 resnet 실험 결과들. shortcut 변화에 따른 실험결과가 흥미롭다. shortcut에 변화를 줄 수 있는건 결국 dimension이 변할 때인데 이 때 (A) zero-padding을 하거나 (B) projection을 사용할 수 있다. A, B, C 변화에 따른 성능 차이가 미미하므로 shortcut의 방법은 크게 중요하지 않음을 알 수 있다. C의 경우 모델 크기만 늘리게 되므로 논문에서는 B를 사용한다.
<img src="https://www.dropbox.com/s/mddj8rhcnr12fjp/Screenshot%202018-10-10%2000.43.50.png?dl=1">
<img src="https://www.dropbox.com/s/eg4db2yz3mr7qhe/Screenshot%202018-10-10%2000.44.12.png?dl=1">

- resnet-34까지는 다음 그림의 왼쪽처럼 block을 만들고 resnet-50부터는 오른쪽처럼 block을 만든다. 더 깊게 네트워크를 쌓기 위해 1x1 convolution을 사용한다. 그렇게하면 parameter 숫자의 증가를 어느정도 막을 수 있다. 152 layer까지 쌓아도 vgg보다 모델 크기가 작다고 한다..
<img src="https://www.dropbox.com/s/5ytxdqsq73alruz/Screenshot%202018-10-10%2000.46.16.png?dl=1">

- CIFAR-10 에서의 실험 결과는 다음과 같다. 최고 성능은 110 layer resnet이다. 
<img src="https://www.dropbox.com/s/pihvoi3pn1xyk48/Screenshot%202018-10-12%2022.55.37.png?dl=1">

<br/>

### Suplementaty Material
- resnet의 skip connection을 분석하는 논문이 이후에 나왔다. [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)
- 관련된 한국말로 된 post는 다음과 같다. [https://kangbk0120.github.io/articles/2018-01/identity-mapping-in-deep-resnet](https://kangbk0120.github.io/articles/2018-01/identity-mapping-in-deep-resnet)
