---
layout: post
title: "Deep-Vision 기초 시리즈 1: Resnet"
subtitle: "Deep Residual Learning for Image Recognition"
categories: paper
tags: dl
comments: true
---

현재 딥러닝은 vision 분야에서 탁월한 성능을 보이며 NLP, Robotics, Sound 분야로 그 영향력을 확장해나가고 있다. 각 분야에서 딥러닝은 다른 모습으로 활용이 되고 있지만 그 기본이 되는 것은 거의 vision 분야에서 나온다. 따라서 vision 분야에서 기본이 되는 논문을 읽어보고 직접 구현해보는 것은 앞으로의 실력 향상에 상당한 도움이 된다. 따라서 이 post에서는 vision 분야의 특정 task들의 baseline이 되는 논문을 살펴보고 코드를 리뷰하고자 한다. 이 series의 이름은 Deep-Vision 기초 시리즈이다. 이 series와 관련된 코드는 다음 github repository에서 볼 수 있다. 

- [Deep-Vision github code](https://github.com/dnddnjs/pytorch-vision) 


## 논문 제목: Deep Residual Learning for Image Recognition [2015 December]

<img src="https://www.dropbox.com/s/b0dp6tse95zudzw/Screenshot%202018-10-09%2020.54.11.png?dl=1">
- 논문 저자: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun(Microsoft Research)
- 논문 링크: [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)


Resnet은 VGG와 함께 대부분의 Deep-Network에서 기본이 되는 네트워크 구조이다. Resnet 이후의 네트워크 구조는 거의 Resnet의 변형이라고 볼 수 있다. 따라서 이 구조에 대해서 잘 아는 것이 중요하다. 

</br>

### Abstract

- 이전보다 Deep한 neural network를 training하게 해줌
- 기존 문제를 layer input을 reference로 한 residual function을 학습하는 문제로 바꿈
- 그랬더니 더 최적화하기 쉽고 더 정확도가 높음
- ILSVRC 2015 classification task에서 1등함
- COCO object detection dataset에서 28% 개선

</br>

### Introduction

- degradation problem: 네트워크 깊이가 증가하는데 정확도는 정체되다가 빠르게 감소하는 현상
  - 이 문제는 overfitting으로 인한 문제가 아님 (왜 그렇지?)
  - 실험적으로 layer가 깊어지면 training error도 증가함

<img src="https://www.dropbox.com/s/06xom9u3umodycz/Screenshot%202018-10-09%2021.16.01.png?dl=1">

- 이 논문에서는 degradation 문제를 해결하기 위해 "deep residual learning" 구조를 제안함
- 원래 F(x)를 mapping 했다면 residual connection을 사용하면 F(x) + x를 mapping 함.

<img src="https://www.dropbox.com/s/6acjshs76hb08gj/Screenshot%202018-10-09%2021.20.46.png?dl=1">